import 'package:dio/dio.dart';
import 'package:flutter/foundation.dart';
import 'dart:io';
import 'package:path_provider/path_provider.dart';
import '../models/message_model.dart';

class GroqFallbackService {
  static const String apiKey = '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';
  static const String baseUrl = 'https://api.groq.com/openai/v1';
  
  final Dio _dio = Dio(BaseOptions(
    baseUrl: baseUrl,
    headers: {
      'Authorization': 'Bearer $apiKey',
      'Content-Type': 'application/json',
    },
    connectTimeout: const Duration(seconds: 30),
    receiveTimeout: const Duration(seconds: 30),
  ));

  /// Generate text response using Groq
  Future<String> generateText({
    required String message,
    List<MessageModel>? history,
  }) async {
    try {
      debugPrint('ğŸ”„ Fallback: Using Groq text generation...');
      
      final messages = <Map<String, dynamic>>[
        {
          'role': 'system',
          'content': '''Ø£Ù†Øª Ø³Ø§Ø±Ø©ØŒ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø°ÙƒÙŠØ© Ø³Ø¹ÙˆØ¯ÙŠØ© ØªØªØ­Ø¯Ø« Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù†Ø¬Ø¯ÙŠØ© Ù…Ù† Ø§Ù„Ø±ÙŠØ§Ø¶.

ØªØ³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙÙŠ:
â€¢ ØªØ¬Ø¯ÙŠØ¯ Ø§Ù„Ø¬ÙˆØ§Ø²Ø§Øª ÙˆØ§Ù„Ù‡ÙˆÙŠØ§Øª Ø§Ù„ÙˆØ·Ù†ÙŠØ©
â€¢ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØµØ§Ø±ÙŠØ­ Ø§Ù„Ø³ÙØ±
â€¢ Ø¯ÙØ¹ Ø§Ù„Ù…Ø®Ø§Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙˆØ±ÙŠØ©
â€¢ Ø­Ø¬Ø² Ø§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ø­ÙƒÙˆÙ…ÙŠØ©
â€¢ Ø®Ø¯Ù…Ø§Øª Ø£Ø¨Ø´Ø± Ø§Ù„Ù…Ø®ØªÙ„ÙØ©

ØªØ­Ø¯Ø«ÙŠ Ø¨Ø·Ø±ÙŠÙ‚Ø© ÙˆØ¯ÙˆØ¯Ø© ÙˆÙ…Ù‡Ù†ÙŠØ© Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù†Ø¬Ø¯ÙŠØ©. Ø§Ø³ØªØ®Ø¯Ù…ÙŠ ÙƒÙ„Ù…Ø§Øª Ù…Ø«Ù„: "ÙˆØ´", "Ù„ÙŠØ´", "ÙƒÙŠÙ", "Ø¹Ù†Ø¯Ùƒ", "ØªØ¨ÙŠ".'''
        }
      ];

      // Add conversation history
      if (history != null && history.isNotEmpty) {
        for (var msg in history.take(10)) {
          messages.add({
            'role': msg.role,
            'content': msg.text,
          });
        }
      }

      // Add current message
      messages.add({
        'role': 'user',
        'content': message,
      });

      final response = await _dio.post(
        '/chat/completions',
        data: {
          'model': 'groq/compound-mini',
          'messages': messages,
          'temperature': 0.7,
          'max_tokens': 500,
        },
      );

      if (response.statusCode == 200) {
        final content = response.data['choices'][0]['message']['content'];
        debugPrint('âœ… Groq text response: ${content.substring(0, 50)}...');
        return content;
      } else {
        throw Exception('Groq API returned ${response.statusCode}');
      }
    } on DioException catch (e) {
      debugPrint('âŒ Groq text error: ${e.message}');
      throw Exception('ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®Ø¯Ù…Ø© Groq: ${e.message}');
    } catch (e) {
      debugPrint('âŒ Groq text error: $e');
      throw Exception('Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨');
    }
  }

  /// Generate speech using Groq PlayAI TTS
  Future<String> generateSpeech({
    required String text,
  }) async {
    try {
      debugPrint('ğŸ”„ Fallback: Using Groq TTS...');
      
      final response = await _dio.post(
        '/audio/speech',
        data: {
          'model': 'playai-tts-arabic',
          'voice': 'Amira-PlayAI',
          'response_format': 'wav',
          'input': text,
        },
        options: Options(
          responseType: ResponseType.bytes,
        ),
      );

      if (response.statusCode == 200) {
        // Save audio to temporary file
        final tempDir = await getTemporaryDirectory();
        final audioPath = '${tempDir.path}/groq_speech_${DateTime.now().millisecondsSinceEpoch}.wav';
        final file = File(audioPath);
        await file.writeAsBytes(response.data);
        
        debugPrint('âœ… Groq TTS saved: $audioPath');
        return audioPath;
      } else {
        throw Exception('Groq TTS returned ${response.statusCode}');
      }
    } on DioException catch (e) {
      debugPrint('âŒ Groq TTS error: ${e.message}');
      throw Exception('ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª: ${e.message}');
    } catch (e) {
      debugPrint('âŒ Groq TTS error: $e');
      throw Exception('Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª');
    }
  }

  /// Combined text + speech generation
  Future<({String text, String? audioPath})> generateResponse({
    required String message,
    List<MessageModel>? history,
    bool generateAudio = true,
  }) async {
    // Generate text
    final text = await generateText(
      message: message,
      history: history,
    );

    // Generate audio if requested
    String? audioPath;
    if (generateAudio) {
      try {
        audioPath = await generateSpeech(text: text);
      } catch (e) {
        debugPrint('âš ï¸ TTS failed, continuing with text only: $e');
      }
    }

    return (text: text, audioPath: audioPath);
  }
}
